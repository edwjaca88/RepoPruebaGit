{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "from pycaret.regression import *\n",
    "from pycaret.clustering import *\n",
    "from pycaret.anomaly import *\n",
    "from pycaret.timeseries import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Índice\n",
    "1. [Clasificación](#clasificación)\n",
    "2. [Regresión](#Regresión)\n",
    "3. [Clustering](#clustering)\n",
    "4. [Detección de Anomalías](#anomaly-detection)\n",
    "5. [Series de Tiempo](#series-de-tiempo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos (reemplaza 'nombre_del_archivo.csv' con el nombre de tu archivo de datos)\n",
    "data = pd.read_csv('nombre_del_archivo.csv')\n",
    "\n",
    "\n",
    "# Cargar los datos (reemplaza 'nombre_del_archivo.csv' con el nombre de tu archivo de datos)\n",
    "data = pd.read_csv('nombre_del_archivo.csv')\n",
    "\n",
    "# Paso 2: Configurar el entorno de PyCaret\n",
    "# Seleccionar la columna objetivo (target) y configurar la sesión de PyCaret\n",
    "exp_clf = setup(data, target='columna_objetivo', session_id=42,\n",
    "                normalize=True, \n",
    "                categorical_features=['columna_categorica_1', 'columna_categorica_2'],\n",
    "                feature_selection=True, feature_selection_threshold=0.8,\n",
    "                fix_imbalance=True)\n",
    "\n",
    "# Paso 3: Comparar modelos con validación cruzada\n",
    "best_model = compare_models(cross_validation=True)\n",
    "\n",
    "# Paso 4: Crear el modelo final con el mejor algoritmo seleccionado y minibatch\n",
    "# Reemplaza 'batch_size' con el tamaño deseado del minibatch (por ejemplo, 32, 64, etc.)\n",
    "final_model = create_model(best_model, cross_validation=True, batch_size='batch_size')\n",
    "\n",
    "# Paso 5: Sintonizar el modelo (opcional)\n",
    "tuned_model = tune_model(final_model)\n",
    "\n",
    "# Paso 6: Evaluar el modelo\n",
    "evaluate_model(tuned_model)\n",
    "\n",
    "# Paso 7: Guardar el modelo entrenado\n",
    "# Reemplaza 'nombre_del_modelo_entrenado' con el nombre que deseas para el archivo del modelo\n",
    "save_model(tuned_model, 'nombre_del_modelo_entrenado')\n",
    "\n",
    "# Paso 8: Realizar predicciones en nuevos datos\n",
    "# Cargar nuevos datos (reemplaza 'nuevos_datos.csv' con el nombre de tu archivo de nuevos datos)\n",
    "new_data = pd.read_csv('nuevos_datos.csv')\n",
    "\n",
    "# Realizar predicciones en los nuevos datos\n",
    "predictions = predict_model(tuned_model, data=new_data)\n",
    "\n",
    "# Ver las predicciones\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos (reemplaza 'nombre_del_archivo.csv' con el nombre de tu archivo de datos)\n",
    "data = pd.read_csv('nombre_del_archivo.csv')\n",
    "\n",
    "# Paso 2: Configurar el entorno de PyCaret\n",
    "# Seleccionar la columna objetivo (target) y configurar la sesión de PyCaret\n",
    "exp_reg = setup(data, target='columna_objetivo', session_id=42,\n",
    "                normalize=True, \n",
    "                categorical_features=['columna_categorica_1', 'columna_categorica_2'],\n",
    "                feature_selection=True, feature_selection_threshold=0.8)\n",
    "\n",
    "# Paso 3: Comparar modelos con validación cruzada\n",
    "best_model = compare_models(cross_validation=True)\n",
    "\n",
    "# Paso 4: Crear el modelo final con el mejor algoritmo seleccionado y validación cruzada\n",
    "final_model = create_model(best_model, cross_validation=True)\n",
    "\n",
    "# Paso 5: Sintonizar el modelo (opcional)\n",
    "tuned_model = tune_model(final_model)\n",
    "\n",
    "# Paso 6: Evaluar el modelo\n",
    "evaluate_model(tuned_model)\n",
    "\n",
    "# Paso 7: Guardar el modelo entrenado\n",
    "# Reemplaza 'nombre_del_modelo_entrenado' con el nombre que deseas para el archivo del modelo\n",
    "save_model(tuned_model, 'nombre_del_modelo_entrenado')\n",
    "\n",
    "# Paso 8: Realizar predicciones en nuevos datos\n",
    "# Cargar nuevos datos (reemplaza 'nuevos_datos.csv' con el nombre de tu archivo de nuevos datos)\n",
    "new_data = pd.read_csv('nuevos_datos.csv')\n",
    "\n",
    "# Realizar predicciones en los nuevos datos\n",
    "predictions = predict_model(tuned_model, data=new_data)\n",
    "\n",
    "# Ver las predicciones\n",
    "print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos (reemplaza 'nombre_del_archivo.csv' con el nombre de tu archivo de datos)\n",
    "data = pd.read_csv('nombre_del_archivo.csv')\n",
    "\n",
    "# Paso 2: Configurar el entorno de PyCaret para clustering\n",
    "# No es necesario seleccionar una columna objetivo (target) en clustering\n",
    "exp_clu = setup(data, session_id=42, normalize=True)\n",
    "\n",
    "# Paso 3: Comparar modelos de clustering\n",
    "best_model = compare_models()\n",
    "\n",
    "# Paso 4: Crear el modelo final con el mejor algoritmo seleccionado\n",
    "final_model = create_model(best_model)\n",
    "\n",
    "# Paso 5: Asignar las etiquetas de clusters a los datos originales\n",
    "clustered_data = assign_model(final_model)\n",
    "\n",
    "# Paso adicional: Cargar nuevos datos para asignar etiquetas de clusters\n",
    "# Cargar nuevos datos (reemplaza 'nuevos_datos.csv' con el nombre de tu archivo de nuevos datos)\n",
    "new_data = pd.read_csv('nuevos_datos.csv')\n",
    "\n",
    "# Asignar etiquetas de clusters a los nuevos datos\n",
    "new_data_with_labels = predict_model(final_model, data=new_data)\n",
    "\n",
    "# Ver las etiquetas de clusters asignadas a los nuevos datos\n",
    "print(new_data_with_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar los datos (reemplaza 'nombre_del_archivo.csv' con el nombre de tu archivo de datos)\n",
    "data = pd.read_csv('nombre_del_archivo.csv')\n",
    "\n",
    "# Paso 2: Configurar el entorno de PyCaret para detección de anomalías\n",
    "exp_ano = setup(data, session_id=42, normalize=True, ignore_features=['columna_no_relevante'])\n",
    "\n",
    "# Paso 3: Comparar modelos de detección de anomalías\n",
    "best_model = compare_models()\n",
    "\n",
    "# Paso 4: Crear el modelo final con el mejor algoritmo seleccionado\n",
    "final_model = create_model(best_model)\n",
    "\n",
    "# Paso 5: Detección de anomalías en los datos originales\n",
    "anomaly_scores = assign_model(final_model)\n",
    "\n",
    "# Paso adicional: Detección de anomalías en nuevos datos\n",
    "# Cargar nuevos datos (reemplaza 'nuevos_datos.csv' con el nombre de tu archivo de nuevos datos)\n",
    "new_data = pd.read_csv('nuevos_datos.csv')\n",
    "\n",
    "# Detección de anomalías en los nuevos datos\n",
    "new_data_anomaly_scores = predict_model(final_model, data=new_data)\n",
    "\n",
    "# Ver los resultados de detección de anomalías en los datos originales y nuevos datos\n",
    "print(anomaly_scores)\n",
    "print(new_data_anomaly_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series de Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('nombre_del_archivo.csv')\n",
    "\n",
    "# Paso 2: Configurar el entorno de PyCaret para series de tiempo\n",
    "exp_ts = setup(data, session_id=42, target='columna_objetivo', \n",
    "               categorical_features=['columna_categorica_1', 'columna_categorica_2'],\n",
    "               fold_strategy='timeseries', fold=3, data_split_shuffle=False)\n",
    "\n",
    "# Paso 3: Comparar modelos de series de tiempo\n",
    "best_model = compare_models()\n",
    "\n",
    "# Paso 4: Crear el modelo final con el mejor algoritmo seleccionado\n",
    "final_model = create_model(best_model)\n",
    "\n",
    "# Paso 5: Sintonizar el modelo (opcional)\n",
    "tuned_model = tune_model(final_model)\n",
    "\n",
    "# Paso 6: Evaluar el modelo\n",
    "evaluate_model(tuned_model)\n",
    "\n",
    "# Paso 7: Guardar el modelo entrenado (opcional)\n",
    "# Reemplaza 'nombre_del_modelo_entrenado' con el nombre que deseas para el archivo del modelo\n",
    "save_model(tuned_model, 'nombre_del_modelo_entrenado')\n",
    "\n",
    "# Paso 8: Realizar predicciones en nuevos datos de series de tiempo\n",
    "# Cargar nuevos datos de series de tiempo (reemplaza 'nuevos_datos.csv' con el nombre de tu archivo de nuevos datos)\n",
    "new_data = pd.read_csv('nuevos_datos.csv')\n",
    "\n",
    "# Realizar predicciones en los nuevos datos de series de tiempo\n",
    "predictions = predict_model(tuned_model, data=new_data)\n",
    "\n",
    "# Ver las predicciones de series de tiempo\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
