{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos (reemplaza 'nombre_del_archivo.csv' con el nombre de tu archivo de datos)\n",
    "data = pd.read_csv('nombre_del_archivo.csv')\n",
    "\n",
    "# Paso 2: Dividir los datos en características (X) y etiquetas (y)\n",
    "X = data.drop('etiqueta', axis=1)\n",
    "y = data['etiqueta']\n",
    "\n",
    "# Paso 3: Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Paso 4: Crear un pipeline con modelos para comparar y seleccionar\n",
    "models = [('Logistic Regression', LogisticRegression()),\n",
    "          ('Support Vector Machine', SVC(probability=True)),\n",
    "          ('Random Forest', RandomForestClassifier())]\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), (name, model)])\n",
    "    \n",
    "    # Entrenar el modelo por batch (opcional)\n",
    "    # Tamaño del minibatch (batch_size)\n",
    "    batch_size = 32\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i + batch_size]\n",
    "        y_batch = y_train[i:i + batch_size]\n",
    "        pipeline.fit(X_batch, y_batch)\n",
    "    \n",
    "    # Entrenar el modelo completo en el conjunto de entrenamiento\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Validación cruzada (opcional)\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Métricas de rendimiento\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results.append(roc_auc)\n",
    "    names.append(name)\n",
    "    \n",
    "    print(f\"Modelo: {name}\")\n",
    "    print(\"ROC AUC:\", roc_auc)\n",
    "    print(\"CV Scores:\", cv_scores)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Paso 5: Comparar y seleccionar el mejor modelo\n",
    "best_model_name = names[np.argmax(results)]\n",
    "best_model = [model[1] for model in models if model[0] == best_model_name][0]\n",
    "\n",
    "print(f\"Mejor Modelo: {best_model_name}\")\n",
    "\n",
    "# Paso 6: Entrenar el mejor modelo en el conjunto de entrenamiento completo\n",
    "best_pipeline = Pipeline([('scaler', StandardScaler()), (best_model_name, best_model)])\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Paso 7: Evaluar el mejor modelo en el conjunto de prueba\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "y_pred_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Mejor Modelo: {best_model_name}\")\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Paso 8: Gráficas para observar el rendimiento del mejor modelo\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'{best_model_name} (area = {roc_auc_score(y_test, y_pred_proba):.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
