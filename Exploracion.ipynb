{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "1. [LECTURA DE ARCHIVOS CON PANDAS](#lectura-de-archivos-con-pandas)  \n",
    "   1.1 [USO DE OS](#uso-de-os)  \n",
    "   1.1.1[LECTURA UN SOLO ARCHIVO](#lectura-de-un-solo-archivo)  \n",
    "   1.1.2[LECTURA MÚLTIPLES ARCHIVOS](#lectura-multiples-archivos)  \n",
    "2. [PANDAS-PROFILING](#usando-pandas-profiling)  \n",
    "3. [LIMPIEZA DE DATOS](#limpiexza-de-datos)  \n",
    "   3.1[DUPLICADOS](#drop-duplicates)  \n",
    "   3.2[NULOS](#manejo-de-valores-nulos)  \n",
    "4. [ENCODERS](#transformación-de-variables-categoricas-a-númericas)  \n",
    "   4.1[sckitlearn](#usando-sckitlearn)  \n",
    "   4.2[CategoryEncoders](#usando-librerïa-category_encoders)  \n",
    "5. [NORMALIZACIÓN y ESTÁNDARIZACIÓN](#estandarizaciön-y-normalizaciön)  \n",
    "6. [PDB](#pdb)\n",
    "7. [MANEJO BÁSICO DF DF](#manejo-básico-df)  \n",
    "   7.1[FUNCIONES LAMBDA](#funciones-lambda)  \n",
    "   7.2[MAPEOS EN DF](#map-apply-applymap)  \n",
    "   7.3[TABLAS CRUZADAS](#tablas-cruzadas)  \n",
    "8. [GRÁFICOS CON PLOTLY EXPRESS](#gráficos-con-plotly-express)  \n",
    "   8.1[BARPLOT](#bar-plot)  \n",
    "   8.2[LINEPLOT](#line-plot)  \n",
    "   8.3[PIEPLOT](#pie-plot)  \n",
    "   8.4[HEATMAP](#heat-map)  \n",
    "   8.5[GRAFICOS GRUPOS](#comparación)\n",
    "9. [FECHAS](#fechas)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LECTURA DE ARCHIVOS CON PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USO DE OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = \"/ruta/del/directorio\"\n",
    "lista_archivos = os.listdir(directorio)\n",
    "print(lista_archivos)\n",
    "## DIRECTORIO ACTUAL\n",
    "current_directory=os.getcwd()\n",
    "## cambio de directorio\n",
    "# Nuevo directorio al que deseas cambiar\n",
    "nuevo_directorio = \"/ruta/del/nuevo/directorio\"\n",
    "# Cambiar el directorio de trabajo\n",
    "os.chdir(nuevo_directorio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURA DE UN SOLO ARCHIVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo CSV\n",
    "def read_csv_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Leer archivo JSON\n",
    "def read_json_file(file_path):\n",
    "    df = pd.read_json(file_path)\n",
    "    return df\n",
    "\n",
    "# Leer archivo Parquet\n",
    "def read_parquet_file(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    return df\n",
    "\n",
    "# Leer otros tipos de archivos según su extensión\n",
    "def read_file(file_path):\n",
    "    file_extension = file_path.split(\".\")[-1]\n",
    "    if file_extension == \"csv\":\n",
    "        return read_csv_file(file_path)\n",
    "    elif file_extension == \"json\":\n",
    "        return read_json_file(file_path)\n",
    "    elif file_extension == \"parquet\":\n",
    "        return read_parquet_file(file_path)\n",
    "    else:\n",
    "        print(f\"Tipo de archivo no soportado: {file_extension}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURA MULTIPLES ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivos CSV\n",
    "def read_csv_files(file_pattern):\n",
    "    csv_files = glob.glob(file_pattern)\n",
    "    dfs = [pd.read_csv(file) for file in csv_files]\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "# Leer archivos JSON\n",
    "def read_json_files(file_pattern):\n",
    "    json_files = glob.glob(file_pattern)\n",
    "    dfs = [pd.read_json(file) for file in json_files]\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "# Leer archivos Parquet\n",
    "def read_parquet_files(file_pattern):\n",
    "    parquet_files = glob.glob(file_pattern)\n",
    "    dfs = [pd.read_parquet(file) for file in parquet_files]\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "# Leer otros tipos de archivos según su extensión\n",
    "def read_files(file_pattern):\n",
    "    file_extension = file_pattern.split(\".\")[-1]\n",
    "    if file_extension == \"csv\":\n",
    "        return read_csv_files(file_pattern)\n",
    "    elif file_extension == \"json\":\n",
    "        return read_json_files(file_pattern)\n",
    "    elif file_extension == \"parquet\":\n",
    "        return read_parquet_files(file_pattern)\n",
    "    else:\n",
    "        print(f\"Tipo de archivo no soportado: {file_extension}\")\n",
    "        return None\n",
    "\n",
    "# Ejemplo de uso para leer y concatenar todos los archivos CSV en un directorio específico\n",
    "#directory_path_csv = \"directorio_donde_se_encuentran_los_csv/*.csv\"\n",
    "#concatenated_df_csv = read_files(directory_path_csv)\n",
    "\n",
    "# Ejemplo de uso para leer y concatenar todos los archivos JSON en un directorio específico\n",
    "#directory_path_json = \"directorio_donde_se_encuentran_los_json/*.json\"\n",
    "#concatenated_df_json = read_files(directory_path_json)\n",
    "\n",
    "# Ejemplo de uso para leer y concatenar todos los archivos Parquet en un directorio específico\n",
    "#directory_path_parquet = \"directorio_donde_se_encuentran_los_parquet/*.parquet\"\n",
    "#concatenated_df_parquet = read_files(directory_path_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USANDO PANDAS PROFILING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargo df de pruba\n",
    "def read_csv_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "df=read_csv_file('gait.csv')\n",
    "data = pd.util.testing.makeTimeDataFrame(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar el informe de Pandas Profiling\n",
    "profile = ProfileReport(data)\n",
    "# Guardar el informe en un archivo HTML (opcional)\n",
    "profile.to_file(\"informe.html\")\n",
    "# Visualiza reporte en upyter\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIMPIEXZA DE DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELimina duplicados de todas las columnas\n",
    "df.drop_duplicates(inplace=True)\n",
    "# Elimina duplicados de columnas especificas\n",
    "df_sin_duplicados_subset = df.drop_duplicates(subset=['A', 'B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MANEJO DE VALORES NULOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores nulos\n",
    "df_sin_nulos_filas = df.dropna()\n",
    "\n",
    "# Eliminar columnas con valores nulos\n",
    "df_sin_nulos_columnas = df.dropna(axis=1)\n",
    "\n",
    "# Rellenar valores faltantes con un valor específico\n",
    "df_rellenado_valor = df.fillna(0)\n",
    "\n",
    "# Rellenar valores faltantes con el valor medio de la columna 'A'\n",
    "df_rellenado_media = df.fillna(df['A'].mean())\n",
    "\n",
    "# Realizar interpolación lineal para rellenar valores faltantes\n",
    "df_interpolado = df.interpolate()\n",
    "\n",
    "# Reemplazar los valores nulos con el valor -1\n",
    "df_reemplazado = df.replace(to_replace=None, value=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación de Variables Categoricas a Númericas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USANDO SCKITLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAUNDO TENGO CATEGORIAS Y QUIERO UNA COLUMNA CON ETIQUETA ÜNICA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = {'fruta': ['manzana', 'plátano', 'manzana', 'uva', 'plátano']}\n",
    "df = pd.DataFrame(data)\n",
    "# Aplicar Label Encoding a la columna 'fruta'\n",
    "label_encoder = LabelEncoder()\n",
    "df['fruta_encoded'] = label_encoder.fit_transform(df['fruta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GET DUMMIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar One-Hot Encoding a la columna 'fruta' crea columna dummies para cada categoría\n",
    "df_one_hot = pd.get_dummies(df, columns=['fruta'], prefix='fruta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASO ORDIUNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario de mapeo para codificación ordinal\n",
    "mapeo_ordinal = {'manzana': 1, 'plátano': 2, 'uva': 3}\n",
    "# Aplicar codificación ordinal a la columna 'fruta'\n",
    "df['fruta_encoded_ordinal'] = df['fruta'].map(mapeo_ordinal)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USANDO LIBRERÏA category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'fruta': ['manzana', 'plátano', 'manzana', 'uva', 'plátano']}\n",
    "df = pd.DataFrame(data)\n",
    "#LLAMO EL ENCODER\n",
    "encoder = ce.OneHotEncoder(cols=['fruta']) #ce.OneHotEncoder\n",
    "df_binary = encoder.fit_transform(df)\n",
    "df_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESTANDARIZACIÖN Y NORMALIZACIÖN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NORMALIZACIÖN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Algoritmos que requieren normalización:\n",
    "K-means\n",
    "Gaussian mixture models\n",
    "Principal component analysis\n",
    "Support vector machines\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = {'feature1': [10, 20, 30, 40, 50],\n",
    "        'feature2': [100, 200, 300, 400, 500]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Aplicar la normalización a las características\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESTANDARIZACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Algoritmos que requieren estandarización:\n",
    "Regresión lineal\n",
    "Regresión logística\n",
    "Árboles de decisión\n",
    "Bosques aleatorios\n",
    "\"\"\"\n",
    "\n",
    "# SE estandariza uso de distribucciones normales\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = {'feature1': [10, 20, 30, 40, 50],\n",
    "        'feature2': [100, 200, 300, 400, 500]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Aplicar la estandarización a las características\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "print(df_standardized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "def suma(a, b):\n",
    "    resultado = a + b\n",
    "    return resultado\n",
    "\n",
    "# Punto de ruptura: pausar la ejecución aquí para inspeccionar variables\n",
    "pdb.set_trace()\n",
    "\n",
    "x = 5\n",
    "y = 10\n",
    "resultado_suma = suma(x, y)\n",
    "\n",
    "# Continuar la ejecución sin detenerse en el punto de ruptura\n",
    "pdb.set_trace()\n",
    "\n",
    "z = 20\n",
    "resultado_suma_z = suma(resultado_suma, z)\n",
    "print(resultado_suma_z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map, Apply, Mapaplly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map aplica función a colecciones como listas o tuplas o diccionarios, sirve para columnas de df ya que son Series\n",
    "def cuadrado(numero):\n",
    "    return numero ** 2\n",
    "\n",
    "numeros = [1, 2, 3, 4, 5]\n",
    "cuadrados = map(cuadrado, numeros)\n",
    "print(list(cuadrados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply es función dependiente de pandas para aplicar funciones a dataframes\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "def suma_cuadrados(x):\n",
    "    return x['A']**2 + x['B']**2\n",
    "# Aplica la función 'suma_cuadrados' a lo largo de las filas (eje 1) del DataFrame\n",
    "df['Suma_Cuadrados'] = df.apply(suma_cuadrados, axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(3,5,7), (2,4,6),(5,8,9)]\n",
    "df = pd.DataFrame(data, columns = ['A','B','C'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY para una sola columna\n",
    "df[\"D\"]=df[\"A\"].apply(lambda x: x*10)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY PARA TOD EL DF\n",
    "df_2=df.apply(lambda x: x*10)\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCIONEs LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES ANÓNIMAS DE FACIL ACCESO \n",
    "cuadrado = lambda x: x**2\n",
    "resultado = cuadrado(5)\n",
    "print(resultado) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJEMPLO CON FILTER\n",
    "numeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Filtrar los números pares de la lista\n",
    "numeros_pares = filter(lambda x: x % 2 == 0, numeros)\n",
    "\n",
    "# Convertir el objeto 'filter' a una lista para imprimir los resultados\n",
    "print(list(numeros_pares))  # Salida: [2, 4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJMEPLO CON SORTED\n",
    "personas = [\n",
    "    {'nombre': 'Juan', 'edad': 30},\n",
    "    {'nombre': 'María', 'edad': 25},\n",
    "    {'nombre': 'Pedro', 'edad': 35},\n",
    "    {'nombre': 'Ana', 'edad': 28}\n",
    "]\n",
    "\n",
    "# Ordenar las personas por edad de menor a mayor\n",
    "personas_ordenadas = sorted(personas, key=lambda x: x['edad'])\n",
    "\n",
    "# Imprimir las personas ordenadas\n",
    "for persona in personas_ordenadas:\n",
    "    print(persona['nombre'], persona['edad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÏON LAMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÖN LAMBDA CON CONDICIONALES Y BUCLES\n",
    "# Función lambda que devuelve la suma de los números pares en un rango dado\n",
    "sumar_pares = lambda x, y: sum(num for num in range(x, y+1) if num % 2 == 0)\n",
    "\n",
    "# Llamar a la función lambda\n",
    "resultado = sumar_pares(1, 10)\n",
    "print(resultado)  # Salida: 30 (2 + 4 + 6 + 8 + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MANEJO BÁSICO DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREACIÖN Y EXPLORACIÓN\n",
    "data = {\n",
    "    'Nombre': ['Juan', 'María', 'Pedro'],\n",
    "    'Edad': [30, 25, 28],\n",
    "    'Ciudad': ['Madrid', 'Barcelona', 'Valencia']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Número de filas y columnas\n",
    "print(df.shape)\n",
    "\n",
    "# Nombres de las columnas\n",
    "print(df.columns)\n",
    "\n",
    "# Tipos de datos de las columnas\n",
    "print(df.dtypes)\n",
    "\n",
    "# Estadísticas básicas del DataFrame\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCESO Y FILTRADO\n",
    "# Acceder a una columna\n",
    "print(df['Nombre'])\n",
    "\n",
    "# Acceder a una fila por índice\n",
    "print(df.loc[0])\n",
    "\n",
    "# Filtrar por condición\n",
    "mayores_de_28 = df[df['Edad'] > 28]\n",
    "print(mayores_de_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDENAR Y REINDEXAR\n",
    "# Ordenar por una columna\n",
    "df_ordenado = df.sort_values(by='Edad', ascending=False)\n",
    "print(df_ordenado)\n",
    "\n",
    "# Reindexar el DataFrame\n",
    "df_reindexado = df.reset_index(drop=True)\n",
    "print(df_reindexado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRÁFICOS CON PLOTLY EXPRESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCATTERPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datos de ejemplo\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [10, 6, 8, 3, 7]\n",
    "\n",
    "# Crear un gráfico de dispersión con Plotly Express (PX)\n",
    "fig = px.scatter(x=x, y=y, labels={'x': 'Eje X', 'y': 'Eje Y'}, title='Gráfico de Dispersión')\n",
    "fig.update_layout(width=500, height=400)  # Dimensiones del gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAR PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de ejemplo\n",
    "categorias = ['A', 'B', 'C', 'D']\n",
    "valores = [10, 6, 8, 3]\n",
    "\n",
    "# Crear un gráfico de barras con Plotly Express (PX)\n",
    "fig = px.bar(x=categorias, y=valores, labels={'x': 'Categorías', 'y': 'Valores'}, title='Gráfico de Barras')\n",
    "fig.update_layout(width=600, height=400)  # Dimensiones del gráfico\n",
    "fig.update_traces(texttemplate='%{y}', textposition='inside')  # Etiquetas internas al gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINE PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de ejemplo\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [10, 6, 8, 3, 7]\n",
    "\n",
    "# Crear un gráfico de línea con Plotly Express (PX)\n",
    "fig = px.line(x=x, y=y, labels={'x': 'Eje X', 'y': 'Eje Y'}, title='Gráfico de Línea')\n",
    "fig.update_layout(width=500, height=400)  # Dimensiones del gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIE PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de ejemplo\n",
    "categorias = ['A', 'B', 'C', 'D']\n",
    "valores = [10, 6, 8, 3]\n",
    "\n",
    "# Crear un gráfico de pastel con Plotly Express (PX)\n",
    "fig = px.pie(names=categorias, values=valores, title='Gráfico de Pastel')\n",
    "fig.update_layout(width=400, height=400)  # Dimensiones del gráfico\n",
    "fig.update_traces(textinfo='percent+label', textposition='inside')  # Etiquetas internas al gráfico\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEAT MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de ejemplo\n",
    "datos = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "\n",
    "# Crear un mapa de calor con Plotly Express (PX)\n",
    "fig = px.imshow(datos, title='Mapa de Calor')\n",
    "fig.update_layout(width=400, height=400)  # Dimensiones del gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datos de ejemplo\n",
    "# Datos de ejemplo\n",
    "categorias = ['A', 'B', 'C', 'D']\n",
    "grupo_1 = [10, 15, 8, 12]\n",
    "grupo_2 = [8, 10, 6, 9]\n",
    "grupo_3 = [12, 14, 10, 11]\n",
    "\n",
    "# Crear un gráfico de barras agrupadas con Plotly Express (PX)\n",
    "fig = px.bar(x=categorias, y=[grupo_1, grupo_2, grupo_3],\n",
    "             labels={'x': 'Categorías', 'y': 'Valores', 'color': 'Grupos'},\n",
    "             title='Comparación de 3 Grupos por Categoría', barmode='group',\n",
    "             color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "\n",
    "# Personalizar etiquetas\n",
    "fig.update_traces(texttemplate='%{y}', textposition='outside')\n",
    "\n",
    "# Personalizar nombres de las leyendas\n",
    "fig.update_layout(legend_title_text='Grupos', legend=dict(title='Grupos'))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(width=600, height=600) \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempo = [1, 2, 3, 4, 5]\n",
    "grupo_1 = [10, 15, 8, 12, 9]\n",
    "grupo_2 = [8, 10, 6, 9, 11]\n",
    "grupo_3 = [12, 14, 10, 11, 7]\n",
    "\n",
    "# Crear un gráfico de líneas múltiples con Plotly Express (PX)\n",
    "fig = px.line(x=tiempo, y=[grupo_1, grupo_2, grupo_3],\n",
    "              labels={'x': 'Tiempo', 'y': 'Valores', 'color': 'Grupos'},\n",
    "              title='Comparación de 3 Grupos a lo largo del Tiempo',\n",
    "              color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "fig.update_layout(width=600, height=600) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLAS CRUZADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Grupo': ['A', 'B', 'A', 'B', 'A'],\n",
    "    'Categoria': ['X', 'Y', 'X', 'Z', 'Z']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "pdb.set_trace()\n",
    "tabla_cruzada = pd.crosstab(df['Grupo'], df['Categoria'], margins=True, margins_name='Total')\n",
    "print(tabla_cruzada)\n",
    "pdb.set_trace()\n",
    "tabla_cruzada = pd.crosstab(df['Grupo'], df['Categoria'], normalize='index')\n",
    "print(tabla_cruzada)\n",
    "pdb.set_trace()\n",
    "data = {\n",
    "    'Grupo': ['A', 'B', 'A', 'B', 'A'],\n",
    "    'Categoria': ['X', 'Y', 'X', 'Z', 'Z'],\n",
    "    'Otro': ['Sí', 'No', 'Sí', 'Sí', 'No']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "tabla_cruzada = pd.crosstab([df['Grupo'], df['Otro']], df['Categoria'])\n",
    "print(tabla_cruzada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FECHAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fechas_str = ['2023-07-30', '2023-07-31', '2023-08-01']\n",
    "fechas_datetime = pd.to_datetime(fechas_str)\n",
    "print(fechas_datetime)\n",
    "\n",
    "# Crear un rango de fechas desde '2023-07-01' hasta '2023-07-10'\n",
    "rango_fechas = pd.date_range(start='2023-07-01', end='2023-07-10')\n",
    "print(rango_fechas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer componentes de Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fechas': fechas_datetime})\n",
    "df['año'] = df['fechas'].dt.year\n",
    "df['mes'] = df['fechas'].dt.month\n",
    "df['día'] = df['fechas'].dt.day\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPERACIONES DELTA TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la fecha 3 días después de una fecha dada\n",
    "fecha_inicial = pd.to_datetime('2023-07-30')\n",
    "dias_despues = pd.Timedelta(days=3)\n",
    "fecha_resultado = fecha_inicial + dias_despues\n",
    "print(fecha_resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado ppor Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar un DataFrame según un rango de fechas\n",
    "df_filtrado = df.loc[(df['fechas'] >= '2023-07-30') & (df['fechas'] <= '2023-07-31')]\n",
    "print(df_filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGRUPADO POR FECHAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con fechas y valores\n",
    "data = {\n",
    "    'fechas': pd.date_range(start='2023-07-01', end='2023-07-10', freq='D'),\n",
    "    'valores': [10, 15, 8, 12, 9, 6, 4, 7, 3, 2]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Agrupar por mes y calcular la suma de valores por mes\n",
    "df_agrupado = df.resample('M', on='fechas').sum()\n",
    "print(df_agrupado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatear Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir objetos datetime en cadenas de texto con formato específico\n",
    "fecha_str = fecha_inicial.strftime('%Y-%m-%d')\n",
    "print(fecha_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir una cadena de texto en un objeto datetime\n",
    "fecha_str = '2023-07-30'\n",
    "fecha_datetime = pd.to_datetime(fecha_str)\n",
    "print(fecha_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar fechas en DataFrames\n",
    "df = pd.DataFrame({'fechas': pd.date_range(start='2023-07-01', periods=5, freq='D')})\n",
    "fecha_comparar = pd.to_datetime('2023-07-03')\n",
    "df['es_mayor'] = df['fechas'] > fecha_comparar\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
